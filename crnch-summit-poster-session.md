# CRNCH Summit Poster Session
The CRNCH Student Poster Session will be held on February 8th, 2024 from 4:40 - 6 PM. We are excited to have a large number of posters from our CRNCH students, and we also are thrilled to be able to feature the work of some of our [CRNCH PhD Fellowship winners](https://crnch.gatech.edu/content/crnch-fellowship).

We note that in some cases, we have not linked posters due to work being under submission or at the presenter's request. 

### 2023-2024 Fellowship Winners

| Student Presenter, Student Authors | Poster Title | Advisor(s) | GT Department | [Poster] [Abstract] |
| ---------------------------------- | ------------ | ---------- | -------------|-------------------|



| Student Presenter, Student Authors | Poster Title | Advisor(s) | GT Department | [Poster] [Abstract] |
| ---------------------------------- | ------------ | ---------- | -------------|-------------------|
| Chaojian Li | On-Device AR/VR 3D Reconstruction and Rendering | Yingyan (Celine) Lin | School of Computer Science | [Poster](../student_poster_session/posters/) [Abstract](#cl) |
| Zishen Wan, Nandhini Chandramoorthy, Karthik Swaminathan, Pin-Yu Chen, Kshitij Bhardwaj, Vijay Janapa Reddi, Arijit Raychowdhury | MulBERRY: Enabling Bit-Error Robustness for Energy-Efficient Multi-Agent Autonomous Systems | Arijit Raychowdhury, Tushar Krishna | Georgia Tech, IBM, LLNL, Harvard | [Poster](../student_poster_session/posters/) [Abstract](#zw) |
| Canlin Zhang, Gauthaman Murali, Sung-Kyu Lim, Tushar Krishna | Improving Scalability of Flexible On-chip Interconnect for DL Accelerators Using Logic-on-Logic 3D ICs | Sung-Kyu Lim; Tushar Krishna | ECE | [Poster](../student_poster_session/posters/) [Abstract](#cz) |
| Francisco Munoz Martinez, Raveesh Garg, Michael Pellauer, Jose L Abellan, Manuel E Acacio, Tushar Krishna | Flexagon: A Reconfigurable Sparse Multi-dataflow Accelerator for DNNs | Tushar Krishna | University of Murcia, Georgia Tech, NVIDIA | [Poster](../student_poster_session/posters/) [Abstract](#fmm) |
| Girish Mururu, Sharjeel Khan, Bodhisatwa Chatterjee, Chao Chen, Chris Porter, Ada Gavrilovska, Santosh Pande | Beacons: An End-to-End Compiler Framework for Predicting and Utilizing Dynamic Loop Characteristics | Santosh Pande and Ada Gavrilovska | School of Computer Science, IBM Research | [Poster](../student_poster_session/posters/) [Abstract](#gm) |
| Mikhail Isaev | Scaling Infrastructure to Support Multi-Trillion Parameter LLM Training | Rich Vuduc |  | [Poster](../student_poster_session/posters/) [Abstract](#mi) |
| Max Dabagia, Christos Papadimitriou, Santosh Vempala | Computation with Sequences of Assemblies | Santosh Vempala | School of Computer Science, Department of Computer Science (Columbia University) | [Poster](../student_poster_session/posters/) [Abstract](#md) |
| Christopher Jawetz, Fatima Chrit, Spencer Bryngelson, Alexander Alexeev | Developing Quantum Computing Algorithms for Modeling Heat Transfer with Phase Change | Alexander Alexeev | ME, CSE | [Poster](../student_poster_session/posters/) [Abstract](#cj) |
| Jinsun Yoo, Anirudh Sarma, Difei Cao, Kartik Sinha, Myungjin Lee, Umakishore Ramachandran | Investigating Multi-Stream FaaS Applications in Geo-Distributed Edge Environments | Umakishore Ramachandran | School of Computer Science, School of Electrical and Computer Engineering | [Poster](../student_poster_session/posters/) [Abstract](#jy) |
| Sri Ranganathan Palaniappan, Tejeshwar Natarajan, Rahul Narayanan; Chacko Abraham, Jeongyeop Han, Mugdha Daftardar, Dorsa Ajami | Neuromorphic Solutions to Reinforcement Learning Problems | Jeffrey Young, Aaron Jezghani | Various GT Departments | [Poster](../student_poster_session/posters/) [Abstract](#srp) |
| Yongnuo Yang, Jeremy Wang, Alexander Contratti | Efficiency and Parallelism on the Lucata Pathfinder with the HPCG Benchmark | Jeffrey Young | School of ECE, School of CS | [Poster](../student_poster_session/posters/) [Abstract](#yy) |
| Narges Alavisamani, Suhas Vittal, Ramin Ayanzadeh, Poulami Das, Moinuddin Qureshi | PROMATCH: Extending the Reach of Real-time MWPM with Adaptive Pre-Decoding for Quantum Error Correction Decoding | Moinuddin Qureshi | School of Computer Science, Department of Electrical and Computer Engineering (University of Texas at Austin) | [Poster](https://github.com/gt-crnch/crnch-summit-2024/blob/main/student_poster_session/posters/R_1DC2R8sI6UQZPAS_CRNCH%20Poster%202024%20-%20Promatch%20-%20Narges.pdf) [Abstract](#na) |
| William Won, Taekyung Heo, Saeed Rashidi, Srinivas Sridharan, Sudarshan Srinivasan, Tushar Krishna | ASTRA-sim2.0: Modeling Hierarchical Networks and Disaggregated Systems for Large-model Training at Scale | Tushar Krishna | Georgia Institute of Technology, NVIDIA, HP Labs, Intel | [Poster](../student_poster_session/posters/) [Abstract](#wwth) |
| Stefan Abi-Karam | Hardware Design for High-Level Synthesis Using Large Language Models | Cong Hao | School of Electrical and Computer Engineering | [Poster](../student_poster_session/posters/) [Abstract](#sak) |
| Hyoukjun Kwon, Krishnakumar Nair, Jamin Seo, Jason Yik, Debabrata Mohapatra, Dongyuan Zhan, Jinook Song, Peter Capak, Peizhao Zhang, Peter Vajda, Colby Banbury, Mark Mazumder, Liangzhen Lai, Ashish Sirasao, Tushar Krishna, Harshit Khaitan, Vikas Chandra, Vijay Janapa Reddi | XRBench: An Extended Reality (XR) Machine Learning Benchmark Suite for the Metaverse | Tushar Krishna | ECE, Georgia Institute of Technology, Meta, Harvard University, University of California, Irvine | [Poster](../student_poster_session/posters/) [Abstract](#hk) |
| Lechen Yu, Feiyang Jin, Vivek Sarkar | Dynamic Analysis of Data Inconsistencies and Data Races in OpenMP Programs | Vivek Sarkar |  | [Poster](../student_poster_session/posters/) [Abstract](#ly) |
| Lakshmi Sathidevi, Cong (Callie) Hao | HW-SW Co-design of Efficient and Scalable Training for Relational Graph Representation Learning​ | Cong (Callie) Hao | ECE, Georgia Tech | [Poster](../student_poster_session/posters/) [Abstract](#ls) |
| Hang Yang, Lingjun Zhu | Back-side Power Delivery Networks with Integrated DC-DC Converter | Cong(Callie) Hao, Sungkyu Lim | ECE, Gatech | [Poster](../student_poster_session/posters/) [Abstract](#hy) |



## Student Abstracts:

<a id="yy">**Yongnuo Yang, Jeremy Wang, Alexander Contratti - "Efficiency and Parallelism on the Lucata Pathfinder with the HPCG Benchmark"**</a>

In a post-Moore era of computing, near-memory architecture offers an alternative path for continuing to improve processor performance. By placing compute elements closer to memory and forgoing a cache hierarchy, near-memory systems address the memory wall problem, where a large disparity exists between processor speed and memory access. The Lucata Pathfinder platform is a multi-node, massively multithreaded system that uses lightweight migratory threads across a Partitioned Global Address Space such that every memory access occurs locally. It is especially well suited for applications involving sparse matrices, where caches struggle, such as the High Performance Conjugate Gradient (HPCG) benchmark. HPCG applies the Conjugate Gradient algorithm to a generated problem and consists of four main mathematical operations: dot product (DDOT), weighted vector sum (WAXPBY), sparse matrix-vector multiplication (SPMV), and the symmetric Gauss-Seidel method (SYMGS). Through program runs on the Pathfinder and emusim, a simulated environment for the Pathfinder, the performance and parallelization of the system are assessed for each of the operations and the benchmark as a whole. The Pathfinder achieves good utilization and load distribution for smaller problem sizes of HPCG. Further work is being done for larger problem sizes to test the scalability and power efficiency of the system.

<a id="cl">**Chaojian Li - "On-Device AR/VR 3D Reconstruction and Rendering"**</a>

"Neural Radiance Field (NeRF) based 3D reconstruction is highly desirable for immersive Augmented and Virtual Reality (AR/VR) applications, but achieving instant (i.e., &lt; 5 seconds) on-device NeRF training and real-time (i.e., &gt; 30 FPS) high-quality NeRF rendering remains a challenge. In this work, we first identify the inefficiency bottleneck during NeRF training: the need to interpolate NeRF embeddings up to 200,000 times from a 3D embedding grid during each training iteration. To alleviate this, we propose an algorithm-hardware co-design acceleration framework that achieves instant on-device NeRF training. Our algorithm decomposes the embedding grid representation in terms of color and density. Our hardware accelerator further reduces the dominant memory accesses for embedding grid interpolation. Moreover, we develop a web-based real-time NeRF rendering viewer to allow the reconstructed scenes can be viewed in cross-platform devices even with out the proposed hardware accelerator."

<a id="zw">**Zishen Wan, Nandhini Chandramoorthy, Karthik Swaminathan, Pin-Yu Chen, Kshitij Bhardwaj, Vijay Janapa Reddi, Arijit Raychowdhury - "MulBERRY: Enabling Bit-Error Robustness for Energy-Efficient Multi-Agent Autonomous Systems"**</a>

"The adoption of autonomous swarms, consisting of a multitude of unmanned aerial vehicles (UAVs), operating in a collaborative manner, has become prevalent in mainstream application domains for both military and civilian purposes. These swarms are expected to collaboratively carry out navigation tasks and employ complex reinforcement learning (RL) models within the stringent onboard size, weight, and power constraints. While techniques such as reducing on-board operating voltage can improve the energy efficiency of both computation and flight missions, they can lead to on-chip bit failures that are detrimental to mission safety and performance.

To this end, we propose MulBERRY, a multi-agent robust learning framework to enhance bit error robustness and energy efficiency for resource-constrained autonomous UAV swarms. MulBERRY supports multi-agent robust learning, both offline and on-device, with adaptive and collaborative agent-server optimizations. For the first time, MulBERRY demonstrates the practicality of robust low-voltage operation on multi-UAV systems leading to energy savings in both compute and mission quality-of-flight. We conduct extensive system-level experiments on autonomous multi-UAV navigation by leveraging algorithm-level robust learning techniques, and hardware-level bit error, thermal, and power characterizations. Through evaluations, we demonstrate that MulBERRY achieves robustness-performance-efficiency co- optimizations for autonomous UAV swarms. We also show that MulBERRY generalizes well across fault patterns, environments, UAV types, UAV agent numbers, and RL policies, with up to 18.97% reduction in flight energy, 22.07% increase in the number of successful missions, and 4.16× processing energy reduction."

<a id="cz">**Canlin Zhang, Gauthaman Murali, Sung-Kyu Lim, Tushar Krishna - "Improving Scalability of Flexible On-chip Interconnect for DL Accelerators Using Logic-on-Logic 3D ICs"**</a>

Deep Learning (DL) Models are becoming more diverse in dimension, shapes, and sizes. To accommodate this trend, flexible interconnect designs have been introduced to DL accelerators to support flexible dataflow. This work identifies the scalability issues of flexible interconnect on 2D IC. We propose three systematic partitioning methods for converting 2D flexible interconnect to 2-tier, Logic-on-Logic 3D designs to improve throughput and energy efficiency. We implemented those methods on two flexible DL accelerator designs. Our EDA results show up to 3× improvement in design frequency and up to a 75% increase in theoretical throughput.

<a id="fmm">**Francisco Munoz Martinez, Michael Pellauer, Jose L Abellan, Manuel E Acacio, Tushar Krishna - "Flexagon: A Reconfigurable Sparse Multi-dataflow Accelerator for DNNs"**</a>

Sparsity is a growing trend in modern DNN models. Existing Sparse-Sparse Matrix Multiplication (SpMSpM) accelerators are tailored to a particular SpMSpM dataflow (i.e., Inner Product, Outer Product or Gustavson’s), that determines theiroverall efficiency. We demonstrate that this static decision inherently results in a suboptimal dynamic solution. This is because different SpMSpM kernels show varying features (i.e.,dimensions, sparsity pattern, sparsity degree), which makes each dataflow better suited to different data sets. In this work we present Flexagon, the first SpMSpM reconfigurable accelerator that is capable of performing SpMSpM computation by using the particular dataflow that best matches each case. Flexagon accelerator is based on a novel Merger-Reduction Network (MRN) that unifies the concept of reducing and merging in the same substrate, increasing efficiency. Additionally, Flexagon also includes a 3-tier memory hierarchy, specifically tailored to the different access characteristics of the input and output compressed matrices. Using detailed cycle-level simulation of contemporary DNN models from a variety of application domains, we show that Flexagon achieves average performance benefits of 4.59x, 1.71x, and 1.35x with respect to the state-of-the-art SIGMA-like, Sparch-like and GAMMA-like accelerators (265% , 67% and 18%, respectively, in terms of average performance/area efficiency)

<a id="gm">**Girish Mururu, Sharjeel Khan, Bodhisatwa Chatterjee, Chao Chen, Chris Porter, Ada Gavrilovska, Santosh Pande - "Beacons: An End-to-End Compiler Framework for Predicting and Utilizing Dynamic Loop Characteristics"**</a>

"Efficient management of shared resources is a critical problem in high-performance computing (HPC) environments. Tackling this problem in a scalable fashion is challenging due to the knowledge needed. The workload scheduler must possess in-depth knowledge about various application resource requirements and runtime phases at fine granularities.
In this work, we show that applications’ resource requirements and execution phase behavior can be captured in a scalable manner at runtime by estimating important program artifacts termed “dynamic loop characteristics”. We present Beacons Framework, an end-to-end compiler and scheduling framework, that estimates dynamic loop characteristics, encapsulates them in compiler-instrumented beacons in an application, and broadcasts them during application runtime, for proactive workload scheduling. Through a combination of compiler analysis and machine learning, we focus on estimating four important loop characteristics: loop trip-count, loop timing, loop memory footprint, and loop data-reuse behavior.
At the backend, Beacons Framework entails a proactive workload scheduler that leverages the runtime information to orchestrate aggressive process co-locations, for maximizing resource concurrency. Our results show that Beacons Framework can predict different loop characteristics with an accuracy of 85% to 95% on average, and the proactive scheduler obtains an average throughput improvement of 1.9x (up to 3.2x) over the state-of-the-art schedulers on an Amazon Graviton2 machine on consolidated workloads involving 1000-10000 co-executing processes, across 51 benchmarks."

<a id="mi">**Mikhail Isaev - "Scaling Infrastructure to Support Multi-Trillion Parameter LLM Training"**</a>

This poster discusses efficient system designs for Large Language Model (LLM) scaling to up to 128 trillion parameters. We use a comprehensive analytical performance model to analyze how such models could be trained on current systems while maintaining 75% Model FLOPS Utilization (MFU). We first show how tensor offloading alone can be used to dramatically increase the size of trainable LLMs. We analyze performance bottlenecks when scaling on systems up to 16,384 GPUs and with models up to 128T parameters. Our findings suggest that current H100 GPUs with 80 GiB of HBM enabled with 512 GiB of tensor offloading capacity allows scaling to 11T-parameter LLMs; and getting to 128T parameters requires 120 GiB of HBM and 2 TiB of offloading memory, yielding 75%+ MFU, which is uncommon even when training much smaller LLMs today.

<a id="md">**Max Dabagia, Christos Papadimitriou, Santosh Vempala - "Computation with Sequences of Assemblies"**</a>

Even as machine learning exceeds human-level performance on many applications, the generality, robustness, and rapidity of the brain's learning capabilities remain unmatched. How cognition arises from neural activity is &lt;em&gt; the&lt;/em&gt; central open question in neuroscience, inextricable from the study of intelligence itself. A simple formal model of neural activity was proposed in Papadimitriou (2020) and has been subsequently shown, through both mathematical proofs and simulations, to be capable of implementing certain simple cognitive operations via the creation and manipulation of assemblies of neurons. However, many intelligent behaviors rely on the ability to recognize, store, and manipulate temporal &lt;em&gt; sequences &lt;/em&gt; of stimuli (planning, language, navigation, to list a few). Here we show that, in the same model, time can be captured naturally as precedence through synaptic weights and plasticity, and, as a result, a range of computations on &lt;em&gt; sequences &lt;/em&gt; of assemblies can be carried out.  In particular, repeated presentation of a sequence of stimuli leads to the memorization of the sequence through corresponding neural assemblies: upon future presentation of any stimulus in the sequence, the corresponding assembly and its subsequent ones will be activated, one after the other, until the end of the sequence.  If the stimulus sequence is presented to two brain areas simultaneously, a scaffolded representation is created, resulting in more efficient memorization and recall, in agreement with cognitive experiments. Finally, we show that any finite state machine can be learned in a similar way, through the presentation of appropriate patterns of sequences.  Through an extension of this mechanism, the model can be shown to be capable of universal computation. We support our analysis with a number of experiments to probe the limits of learning in this model in key ways. Taken together, these results provide a concrete hypothesis for the basis of the brain's remarkable abilities to compute and learn, with sequences playing a vital role.

<a id="cj">**Christopher Jawetz, Fatima Chrit, Spencer Bryngelson, Alexander Alexeev - "Developing Quantum Computing Algorithms for Modeling Heat Transfer with Phase Change"**</a>

Computational Fluid Dynamics (CFD) has long stood as one of the most demanding arenas in computational science, challenging the capabilities of conventional computing architectures with its scale. Despite the significant computational resources dedicated to CFD, the complexity and scale of simulations often necessitate trade-offs in simulation fidelity to achieve results within a practical timeframe. This constraint has fueled the pursuit of more efficient computational approaches, with quantum computing emerging as a particularly promising avenue. Quantum computing, with its ability to create and manipulate superpositions of multiple states simultaneously, offers the potential for exponential acceleration of CFD algorithms. In this context, we have pioneered a novel approach by developing a heat transfer algorithm using the lattice-Boltzmann method, which is well-suited for quantum computing due to its local interactions and inherent parallelism. We use this to investigate quantum spin interactions through a quantum Monte Carlo technique, which achieves a quadratic speedup compared to conventional computational methods. This innovative combination leverages the unique strengths of quantum computing and marks a significant step forward in overcoming the limitations of traditional CFD simulations, potentially transforming the field by enabling higher-fidelity simulations to be conducted more efficiently and rapidly.

<a id="cj">**Jinsun Yoo, Anirudh Sarma, Difei Cao, Kartik Sinha, Myungjin Lee, Umakishore Ramachandran - "Investigating Multi-Stream FaaS Applications in Geo-Distributed Edge Environments"**</a>

"Emerging applications such as collaborative autonomous vehicles or drone navigation require the application to process sensory data and make decisions in machine perception speeds. These applications have stringent latency requirements and network bandwidth, which makes it more viable to serve them on geo-distributed Edge micro data centers on the last mile of the network. However, because the Edge is constrained by the limited and distributed nature of hardware resources, traditional frameworks to serve application on the cloud need to be reimagined. 
Function as a Service (FaaS) is gaining interest, as they have swift scaling capabilities and frees the users from the burden of dedicated resources. However, current FaaS platforms do not provide the abstractions necessary to serve these applications. In addition to the latency and bandwidth constraints, these applications combine inputs from multiple client streams spread across multiple Edge sites, necessitating coordinated data transfer across Edge sites. The clients also move between Edge sites, causing a variance in per-site workload.
In this research we identify the key challenges in realizing FaaS on the Edge with multi-stream applications in geo-distributed edge environments, with a focus on spatio-temporal correctness and client mobility aware resource scheduling. We then propose a programming model that solves these challenges with minimal input from the user."

<a id="srp">**Sri Ranganathan Palaniappan, Tejeshwar Natarajan, Rahul Narayanan; Chacko Abraham, Jeongyeop Han, Mugdha Daftardar, Dorsa Ajami - "Neuromorphic Solutions to Reinforcement Learning Problems"**</a>

"The OpenAI Gymnasium subteam at Rogues Gallery explored the use of a Q-learning model for the Mountain Car environment, a classic problem in reinforcement learning. With the use of the OpenAI Gymnasium library, the subteam implemented and evaluated the performance of the model, as well as investigated the effects of hyperparameter tuning on the learning outcomes. The poster also investigates the potential of a deep Q-learning model and its performance over the Q-learning counterpart."

<a id="yyjw">**Yongnuo Yang, Jeremy Wang, Alexander Contratti - "Efficiency and Parallelism on the Lucata Pathfinder with the HPCG Benchmark"**</a>

"In a post-Moore era of computing, near-memory architecture offers an alternative path for continuing to improve processor performance. By placing compute elements closer to memory and forgoing a cache hierarchy, near-memory systems address the memory wall problem, where a large disparity exists between processor speed and memory access. The Lucata Pathfinder platform is a multi-node, massively multithreaded system that uses lightweight migratory threads across a Partitioned Global Address Space such that every memory access occurs locally. It is especially well suited for applications involving sparse matrices, where caches struggle, such as the High Performance Conjugate Gradient (HPCG) benchmark. HPCG applies the Conjugate Gradient algorithm to a generated problem and consists of four main mathematical operations: dot product (DDOT), weighted vector sum (WAXPBY), sparse matrix-vector multiplication (SPMV), and the symmetric Gauss-Seidel method (SYMGS). Through program runs on the Pathfinder and emusim, a simulated environment for the Pathfinder, the performance and parallelization of the system are assessed for each of the operations and the benchmark as a whole. The Pathfinder achieves good utilization and load distribution for smaller problem sizes of HPCG. Further work is being done for larger problem sizes to test the scalability and power efficiency of the system."

<a id="na">**Narges Alavisamani, Suhas Vittal, Ramin Ayanzadeh, Poulami Das, Moinuddin Qureshi - "PROMATCH: Extending the Reach of Real-time MWPM with Adaptive Pre-Decoding for  Quantum Error Correction Decoding"**</a>

"Fault-tolerant quantum computing relies on Quantum Error Correction (QEC), which encodes logical qubits into data and parity qubits. Error decoding is the process of translating the measured parity bits into types and locations of errors. To prevent a backlog of errors, error decoding must be performed in real-time (i.e., within 1 microsecond on superconducting machines). Minimum Weight Perfect Matching (MWPM) is an accurate decoding algorithm for surface code, and recent research has demonstrated real-time implementations of MWPM (RT-MWPM) for a distance of up to 9. Unfortunately, beyond d=9, the number of flipped parity bits in the syndrome exceeds the capabilities of existing RT-MWPM decoders. In this work, our goal is to enable larger distance RT-MWPM decoders by using adaptive predecoding that converts high hamming-weight syndromes into low hamming-weight syndromes, which are accurately decoded by the RT-MWPM decoder. 
An effective predecoder must balance both accuracy (as any erroneous decoding by the predecoder contributes to the overall logical error-rate, termed as LER) and coverage (as the predecoder must ensure that the hamming weight of the syndrome is within the capability of the final decoder). In this paper, we propose Promatch, a real-time adaptive predecoder that predecodes both simple and complex patterns using a locality-aware, greedy approach. Our approach ensures two crucial factors: 1) high accuracy in prematching flipped bits, ensuring that the decoding accuracy is not hampered by the predecoder, and 2) enough coverage adjusted based on the main decoder’s capability given the time constraints. Promatch represents the first real-time decoding framework capable of decoding surface codes of distances 11 and 13, achieving an LER of 2.6x1e-14 for distance 13. Moreover, we demonstrate that running Promatch concurrently with the recently proposed Astrea-G achieves LER equivalent to MWPM LER, 3.4x1e-15, for distance 13, representing the first real-time accurate decoder for up to a distance of 13."


<a id="wwth">**William Won, Taekyung Heo, Saeed Rashidi, Srinivas Sridharan, Sudarshan Srinivasan, Tushar Krishna - "ASTRA-sim2.0: Modeling Hierarchical Networks and Disaggregated Systems for Large-model Training at Scale"**</a>

"As deep learning models and input data are scaling at an unprecedented rate, it is inevitable to move towards distributed training platforms to fit the model and increase training throughput. State-of-the-art approaches and techniques, such as wafer-scale nodes, multi-dimensional network topologies, disaggregated memory systems, and parallelization strategies, have been actively adopted by emerging distributed training systems. This results in a complex SW/HW co-design stack of distributed training, necessitating a modeling/simulation infrastructure for design-space exploration. In this paper, we extend the open-source ASTRA-sim infrastructure and endow it with the capabilities to model state-of-the-art and emerging distributed training models and platforms. More specifically, (i) we enable ASTRA-sim to support arbitrary model parallelization strategies via a graph-based training-loop implementation, (ii) we implement a parameterizable multi-dimensional heterogeneous topology generation infrastructure with analytical performance estimates enabling simulating target systems at scale, and (iii) we enhance the memory system modeling to support accurate modeling of in-network collective communication and disaggregated memory systems. With such capabilities, we run comprehensive case studies targeting emerging distributed models and platforms. This infrastructure lets system designers swiftly traverse the complex co-design stack and give meaningful insights when designing and deploying distributed training platforms at scale."

<a id="sak">**Stefan Abi-Karam - "Hardware Design for High-Level Synthesis Using Large Language Models"**</a>

"Large language models (LLMs) are extensively used in natural language and programming tasks, with emerging and exciting applications in hardware design, particularly for hardware description languages (HDLs) such as Verilog. However, there has been little focus on utilizing these models for hardware design using high-level synthesis (HLS) ""languages"" and tools.

This study presents the first attempts to explore the use of LLMs for designing HLS hardware kernels that target the Xilinx Vitis HLS tool and FPGA platforms. Our main objectives are twofold: 1) to improve existing hardware kernel performance through code editing, and 2) to generate new hardware kernels from user descriptions and scaffolding code. Our framework includes HLS benchmarks for LLMs, programming abstractions for commercial and open-source LLMs, HLS-specific design evaluation metrics, and programmatic tool interfaces for Vitis HLS and Clang.

In our preliminary evaluation of zero-shot editing, we discovered that current open-source pretrained language models are unable to transform HLS designs without introducing errors and non-synthesizable constructs. The best error observed was 33%, fi not worst for other models. This result emphasizes the need for further research to explore more advanced techniques, such as tool feedback, to maximize the performance of LLMs for HLS design."

<a id="hk">**Hyoukjun Kwon, Krishnakumar Nair, Jamin Seo, Jason Yik, Debabrata Mohapatra, Dongyuan Zhan, Jinook Song, Peter Capak, Peizhao Zhang, Peter Vajda, Colby Banbury, Mark Mazumder, Liangzhen Lai, Ashish Sirasao, Tushar Krishna, Harshit Khaitan, Vikas Chandra, Vijay Janapa Reddi - "XRBench: An Extended Reality (XR) Machine Learning Benchmark Suite for the Metaverse"**</a>

"Real-time multi-task multi-model (MTMM) workloads, a new form of deep learning inference workloads, are emerging for applications areas like extended reality (XR) to support metaverse use cases. These workloads combine user interactivity with computationally complex machine learning (ML) activities. Compared to standard ML applications, these ML workloads present unique difficulties and constraints. Real-time MTMM workloads impose heterogeneity and concurrency requirements on future ML systems and devices, necessitating the development of new capabilities. This project starts from identifying the various characteristics of these real-time MTMM ML workloads and presents an ontology for evaluating the performance of future ML hardware for XR systems. Then, we present XRBench, a collection of MTMM ML tasks, models, and usage scenarios that execute these models in three representative ways: cascaded, concurrent, and cascaded-concurrent for XR use cases. Finally, we emphasize the need for new metrics that capture the requirements properly. We hope that our work will stimulate research and lead to the development of a new generation of ML systems for XR use cases."

<a id="ly">**Lechen Yu, Feiyang Jin, Vivek Sarkar - "Dynamic Analysis of Data Inconsistencies and Data Races in OpenMP Programs"**</a>

"OpenMP is a popular intra-node parallel programming model that supports several
problem decomposition approaches, including task parallelism, data parallelism, and heterogeneous parallelism. When OpenMP introduces new parallel paradigms or features, it must ensure that these additions align with the existing constructs to maintain consistency and avoid unspecified behaviors. New features can result in revisions to the behavior of existing constructs, which may in turn require programmers to re-evaluate their understanding of existing constructs and adapt their code accordingly. Consequently, writing correct OpenMP programs can be challenging even for experienced programmers.

To alleviate the intricacy of writing correct OpenMP programs, this poster outlines
several dynamic analysis techniques that help programmers identify programming errors in OpenMP programs. First, we describe various erroneous usage of device offloading constructs which can lead to an assortment of memory anomalies. Since these memory anomalies can generate disparities between host variables and their corresponding counterparts on accelerator devices, we classify such bugs as data
inconsistencies. By establishing permissible memory accesses on the host and accelerator, this poster introduces a dynamic approach to detect data inconsistencies automatically. The dynamic approach leverages a per-variable state transition model, which can be used to establish the validity of the memory location before executing any memory accesses. Beyond data inconsistencies, this proposal also delves into novel dynamic approaches for identifying data races in OpenMP programs. By extending the SPD3 race detection algorithm, originally designed for async-finish task parallelism, our dynamic race detection approach can handle a large subset of parallel constructs in OpenMP, thereby checking more precise happens-before relations among tasks relative to existing per-thread vector-clock-based approaches."

<a id="ls">**Lakshmi Sathidevi, Cong (Callie) Hao - "HW-SW Co-design of Efficient and Scalable Training for Relational Graph Representation Learning​"**</a>

"Being able to easily store and retrieve knowledge, as well as predict missing information using existing knowledge, is key to enabling a faster pace of R&D across a variety of high-impact domains. Large Language Models (LLMs) are very popular today for their rich context and the amount of knowledge that they are able to encode. However, their rich context comes at the cost of reliability of their predictions --- they tend to hallucinate. We need a reliable, scalable, and compute efficient approach to store and retrieve knowledge, as well as to extrapolate and to systematically reason on existing knowledge. Towards this, large-scale relational graph representation learning holds great promise. Also, for several applications like genomics and drug discovery, the amount of data procured has far surpassed what our current computational capability can handle at reasonable costs. This demands that we design our relational representation learning methods with HW friendliness and scalability in mind. In this work we propose DMRAW --- a co-designed SW model that inductively learns on knowledge graphs via self-supervised relational link prediction. We show that DMRAW is able to remain HW friendly, scalable, and inductive while also improving over popular models like DistMult and RGCN on relational link prediction performance."

<a id="hy">**Hang Yang, Lingjun Zhu - "Back-side Power Delivery Networks with Integrated DC-DC Converter"**</a>

"Backside metallization techniques have been adopted in advanced technologies to mitigate IR-drop. These metal layers on the backside feature lower parasitic resistance, which is ideal to provide power to the cells with minimum IR-drop. This work shows the benefits of backside power delivery networks compared with frontside counterparts. An integrated DC-DC converter is also induced to further mitigate IR-drop from the package and bonding."
